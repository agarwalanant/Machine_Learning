{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agarwalanant/Machine_Learning/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lJi_slUsFfr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "cfdc1f9c-5230-4121-a282-8284098bed70"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DCZNAFFSGfsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "423c3034-ac1c-45b0-f348-e9aa3a1db1a4"
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.superdatascience.com/wp-content/uploads/2017/02/Natural-Language-Processing.zip\n",
        "!unzip Natural-Language-Processing.zip -d gdrive/My\\ \\Drive/MachineLearning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-31 03:27:31--  http://www.superdatascience.com/wp-content/uploads/2017/02/Natural-Language-Processing.zip\n",
            "Resolving www.superdatascience.com (www.superdatascience.com)... 104.27.172.21, 104.27.173.21, 2606:4700:30::681b:ad15, ...\n",
            "Connecting to www.superdatascience.com (www.superdatascience.com)|104.27.172.21|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.superdatascience.com/wp-content/uploads/2017/02/Natural-Language-Processing.zip [following]\n",
            "--2018-10-31 03:27:31--  https://www.superdatascience.com/wp-content/uploads/2017/02/Natural-Language-Processing.zip\n",
            "Connecting to www.superdatascience.com (www.superdatascience.com)|104.27.172.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28604 (28K) [application/zip]\n",
            "Saving to: ‘Natural-Language-Processing.zip’\n",
            "\n",
            "Natural-Language-Pr 100%[===================>]  27.93K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-10-31 03:27:32 (188 KB/s) - ‘Natural-Language-Processing.zip’ saved [28604/28604]\n",
            "\n",
            "Archive:  Natural-Language-Processing.zip\n",
            "replace gdrive/My Drive/MachineLearning/Natural_Language_Processing/natural_language_processing.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "n\n",
            "replace gdrive/My Drive/MachineLearning/__MACOSX/Natural_Language_Processing/._natural_language_processing.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: replace gdrive/My Drive/MachineLearning/Natural_Language_Processing/natural_language_processing.R? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace gdrive/My Drive/MachineLearning/__MACOSX/Natural_Language_Processing/._natural_language_processing.R? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace gdrive/My Drive/MachineLearning/Natural_Language_Processing/Restaurant_Reviews.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace gdrive/My Drive/MachineLearning/__MACOSX/Natural_Language_Processing/._Restaurant_Reviews.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VF95RV9kHDGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2f96e0b3-7b89-434e-c168-dcf9f414e7d1"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re #Regularization\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BGpU1oOpHGif",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"gdrive/My Drive/MachineLearning/Natural_Language_Processing/Restaurant_Reviews.tsv\",delimiter='\\t',quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcBrMqK3HRdF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cleaning the text\n",
        "corpus =[]\n",
        "for i in range(0,1000):\n",
        "  review = re.sub('[^a-zA-Z]',' ',dataset['Review'][i]) #Keeping only alphabet\n",
        "  review=review.lower()\n",
        "  review = review.split()\n",
        "  ps = PorterStemmer()\n",
        "  review = [ ps.stem(word) for word in review if not word in set(stopwords.words('english'))] #converting to root words\n",
        "  review= ' '.join(review)\n",
        "  corpus.append(review) # back to string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NrrATmUuITv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating the bag of words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "X=cv.fit_transform(corpus).toarray()\n",
        "Y= dataset.iloc[:,1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79hyJOjJIrUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRVXuxA4M_4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f379cf45-38cc-4159-8ca7-10a0faceed02"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier=GaussianNB()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(Y_test,y_pred)\n",
        "\n",
        "cm"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[48, 48],\n",
              "       [18, 86]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "W5RR40v6Prb_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}